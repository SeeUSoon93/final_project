{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "067c0322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 라이브러리 불러오기\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 시각화 전 기본 세팅\n",
    "#한글 깨짐\n",
    "plt.rc(\"font\", family=\"Malgun Gothic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b178864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 불러오기\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv', index_col='no')\n",
    "test = pd.read_csv('data/test.csv', index_col='no')\n",
    "train = pd.read_csv('data/train.csv', index_col='no')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea978e4",
   "metadata": {},
   "source": [
    "## 예측할 값 : 개인 소득\n",
    "- income : 50K 초과는 1, 50K 이하는 0 (소득)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc66511",
   "metadata": {},
   "source": [
    "### 컬럼 의미\n",
    "- age - continuous.\n",
    "- workclass(일 유형) : Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "- fnlwgt(일련의 관측 결과를 바탕으로 인구조사국이 부여하는 개인의 가중치): continuous.\n",
    "- education(교육수준) : Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "- education-num(교육수준 번호) : continuous.\n",
    "- marital-status(결혼 상태) : Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "- occupation(직업) : Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "- relationship(가족관계) : Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "- race(인종) : White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "- sex(성별) : Female, Male.\n",
    "- capital-gain(자본 이익) : continuous.\n",
    "- capital-loss(자본 손실) : continuous.\n",
    "- hours-per-week(주당 근무 시간) : continuous.\n",
    "- native-country(국적) : United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee20e888",
   "metadata": {},
   "source": [
    "### value값 띄어쓰기 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f264a463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 띄어쓰기 제거함\n",
    "for i in train.columns : \n",
    "    if train[f'{i}'].dtype == 'object' :\n",
    "        train[f'{i}'] = train[f'{i}'].apply(lambda x: x.replace(' ', '')) # 제거하는 함수\n",
    "    else :\n",
    "        train[f'{i}'] = train[f'{i}']\n",
    "        \n",
    "for i in test.columns : \n",
    "    if test[f'{i}'].dtype == 'object' :\n",
    "        test[f'{i}'] = test[f'{i}'].apply(lambda x: x.replace(' ', '')) # 제거하는 함수\n",
    "    else :\n",
    "        test[f'{i}'] = test[f'{i}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91cb8e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=['Private', 'Self-emp-not-inc', 'Local-gov', '?',\n",
    "       'State-gov', 'Self-emp-inc','Federal-gov','Without-pay','Never-worked']\n",
    "cover_title=['Private', 'Self-emp-not-inc', 'Local-gov', 'Never-worked',\n",
    "       'State-gov', 'Self-emp-inc','Federal-gov','Without-pay','Never-worked']\n",
    "title_dict = dict(zip(title, cover_title))\n",
    "title_dict\n",
    "train['workclass'] = train['workclass'].map(title_dict)\n",
    "test['workclass'] =test['workclass'].map(title_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88bd1491",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=['United-States', 'Haiti', 'Mexico', 'Puerto-Rico', 'Philippines',\n",
    "       '?', 'Germany', 'Peru', 'Ecuador', 'Iran', 'Thailand',\n",
    "       'Dominican-Republic', 'Poland', 'Scotland', 'Italy', 'Jamaica',\n",
    "       'China', 'Portugal', 'Columbia', 'Hungary', 'Vietnam', 'Taiwan',\n",
    "       'Canada', 'Hong', 'Guatemala', 'El-Salvador', 'England',\n",
    "       'Outlying-US(Guam-USVI-etc)', 'India', 'France', 'Cuba', 'Greece',\n",
    "       'Trinadad&Tobago', 'South', 'Japan', 'Yugoslavia', 'Nicaragua',\n",
    "       'Ireland', 'Cambodia', 'Laos', 'Honduras', 'Holand-Netherlands']\n",
    "cover_title=['United-States', 'Haiti', 'Mexico', 'Puerto-Rico', 'Philippines',\n",
    "       'United-States', 'Germany', 'Peru', 'Ecuador', 'Iran', 'Thailand',\n",
    "       'Dominican-Republic', 'Poland', 'Scotland', 'Italy', 'Jamaica',\n",
    "       'China', 'Portugal', 'Columbia', 'Hungary', 'Vietnam', 'Taiwan',\n",
    "       'Canada', 'Hong', 'Guatemala', 'El-Salvador', 'England',\n",
    "       'Outlying-US(Guam-USVI-etc)', 'India', 'France', 'Cuba', 'Greece',\n",
    "       'Trinadad&Tobago', 'South', 'Japan', 'Yugoslavia', 'Nicaragua',\n",
    "       'Ireland', 'Cambodia', 'Laos', 'Honduras', 'Holand-Netherlands']\n",
    "title_dict = dict(zip(title, cover_title))\n",
    "title_dict\n",
    "train['native-country'] = train['native-country'].map(title_dict)\n",
    "\n",
    "test['native-country'] = test['native-country'].map(title_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69e1fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=['Machine-op-inspct', 'Other-service', 'Handlers-cleaners',\n",
    "       'Tech-support', 'Transport-moving', 'Farming-fishing',\n",
    "       'Prof-specialty', 'Priv-house-serv', 'Adm-clerical',\n",
    "       'Protective-serv', 'Exec-managerial', '?', 'Craft-repair', 'Sales',\n",
    "       'Armed-Forces']\n",
    "cover_title=['Machine-op-inspct', 'Other-service', 'Handlers-cleaners',\n",
    "       'Tech-support', 'Transport-moving', 'Farming-fishing',\n",
    "       'Prof-specialty', 'Priv-house-serv', 'Adm-clerical',\n",
    "       'Protective-serv', 'Exec-managerial', 'Prof-specialty', 'Craft-repair', 'Sales',\n",
    "       'Armed-Forces']\n",
    "title_dict = dict(zip(title, cover_title))\n",
    "title_dict\n",
    "train['occupation'] = train['occupation'].map(title_dict)\n",
    "test['occupation'] = test['occupation'].map(title_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d23ee4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('education',axis=1)\n",
    "test = test.drop('education',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b222557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "marital_status = ['Divorced', 'Never-married', 'Married-civ-spouse', 'Separated',\n",
    "       'Married-spouse-absent', 'Widowed', 'Married-AF-spouse']\n",
    "conver_marital_status = ['not-married', 'not-married', 'married', 'not-married', 'not-married', 'not-married','married']\n",
    "marital_status_dict=dict(zip(marital_status, conver_marital_status))\n",
    "\n",
    "train['marital-status']=train['marital-status'].map(marital_status_dict)\n",
    "test['marital-status']=test['marital-status'].map(marital_status_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ac87835",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['relationship'].unique()\n",
    "title=['Not-in-family', 'Husband', 'Unmarried', 'Other-relative',\n",
    "       'Own-child', 'Wife']\n",
    "cover_title=['Not-in-family', 'Married', 'Unmarried', 'Other-relative',\n",
    "       'Own-child', 'Married']\n",
    "title_dict = dict(zip(title, cover_title))\n",
    "train['relationship'] = train['relationship'].map(title_dict)\n",
    "\n",
    "title=['Own-child', 'Wife', 'Husband', 'Not-in-family', 'Unmarried',\n",
    "       'Other-relative']\n",
    "cover_title=['Own-child', 'Married', 'Married', 'Not-in-family', 'Unmarried',\n",
    "       'Other-relative']\n",
    "title_dict = dict(zip(title, cover_title))\n",
    "test['relationship'] = test['relationship'].map(title_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71651442",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0,4,8,12,16] # 범위지정\n",
    "labels = ['e1', 'e2', 'e3', 'e4'] # 라벨지정\n",
    "train['education-num'] = pd.cut(train['education-num'], bins=bins, labels = labels)\n",
    "test['education-num'] = pd.cut(test['education-num'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "097c56da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#  사회 초년생 - age1 [17~30]\\nage1 = [i for i in range(17, 31)]\\ncover_age1 = ['young'] * (31-17)\\n\\n#  중년층 - age2 [31~50]\\nage2 = [i for i in range(31, 51)]\\ncover_age2 = ['middle'] * (51-31)\\n\\n# 노년층 - age3 [51 ~ 90]\\nage3 = [i for i in range(51, 91)]\\ncover_age3 = ['old'] * (91-51)\\n\\nage_dict = dict(zip(age1 + age2 + age3, cover_age1 + cover_age2 + cover_age3))\\n\\ntrain['age']=train['age'].map(age_dict)\\ntest['age']=test['age'].map(age_dict)\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#  사회 초년생 - age1 [17~30]\n",
    "age1 = [i for i in range(17, 31)]\n",
    "cover_age1 = ['young'] * (31-17)\n",
    "\n",
    "#  중년층 - age2 [31~50]\n",
    "age2 = [i for i in range(31, 51)]\n",
    "cover_age2 = ['middle'] * (51-31)\n",
    "\n",
    "# 노년층 - age3 [51 ~ 90]\n",
    "age3 = [i for i in range(51, 91)]\n",
    "cover_age3 = ['old'] * (91-51)\n",
    "\n",
    "age_dict = dict(zip(age1 + age2 + age3, cover_age1 + cover_age2 + cover_age3))\n",
    "\n",
    "train['age']=train['age'].map(age_dict)\n",
    "test['age']=test['age'].map(age_dict)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b76a6fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [i for i in range(0, 101,10)]\n",
    "labels = ['age' + str(i) for i in range(0, 100,10)] # 라벨지정\n",
    "train['age'] = pd.cut(train['age'], bins=bins, labels = labels)\n",
    "test['age'] = pd.cut(test['age'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28bd38d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=['Private', 'Self-emp-not-inc', 'Local-gov', 'State-gov',\n",
    "       'Self-emp-inc', 'Federal-gov', 'Without-pay', 'Never-worked']\n",
    "cover_title=['Private', 'Self-emp', 'gov', 'gov',\n",
    "       'Self-emp', 'gov', 'beggar', 'beggar']\n",
    "title_dict = dict(zip(title, cover_title))\n",
    "train['workclass'] = train['workclass'].map(title_dict)\n",
    "test['workclass'] = test['workclass'].map(title_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45470ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "native_country = ['United-States', 'Haiti', 'Mexico', 'Puerto-Rico', 'Philippines',\n",
    "       'Germany', 'Peru', 'Ecuador', 'Iran', 'Thailand',\n",
    "       'Dominican-Republic', 'Poland', 'Scotland', 'Italy', 'Jamaica',\n",
    "       'China', 'Columbia', 'Hungary', 'Portugal', 'Vietnam', 'Taiwan',\n",
    "       'Canada', 'Hong', 'Guatemala', 'El-Salvador', 'England',\n",
    "       'Outlying-US(Guam-USVI-etc)', 'India', 'France', 'Cuba', 'Greece',\n",
    "       'Trinadad&Tobago', 'South', 'Japan', 'Yugoslavia', 'Nicaragua',\n",
    "       'Ireland', 'Cambodia', 'Laos', 'Honduras', 'Holand-Netherlands']\n",
    "conver_native_country = ['United-States', 'North America', 'Asia', 'Europe', 'North America',\n",
    "                         'North America', 'North America', 'North America', 'Asia', 'Europe',\n",
    "                         'North America', 'Asia', 'Asia', 'North America', 'Europe',\n",
    "                         'Asia', 'South America', 'North America', 'Asia', 'Europe',\n",
    "                        'North America', 'Europe', 'Asia', 'Asia', 'North America',\n",
    "                         'South America', 'Europe', 'Europe', 'South America', 'Asia',\n",
    "                         'Europe', 'Asia', 'North America', 'Asia', 'Europe',\n",
    "                         'Asia', 'South America', 'Europe', 'North America', 'Europe', 'Europe']\n",
    "\n",
    "native_country_dict = dict(zip(native_country, conver_native_country))\n",
    "native_country_dict\n",
    "train['native-country']=train['native-country'].map(native_country_dict)\n",
    "test['native-country']=test['native-country'].map(native_country_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c18e6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('fnlwgt',axis=1)\n",
    "test= test.drop('fnlwgt',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b59a913",
   "metadata": {},
   "source": [
    "- 컬럼순서 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85f163ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제/답 분리\n",
    "X_train = train.loc[:,:'native-country']\n",
    "y_train = train['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6443dbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train) # 0과 1로만 이루어진 열을 생성\n",
    "X_test = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de9f2720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7201c1e3",
   "metadata": {},
   "source": [
    "그리드 서치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38f9bdea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AdaBoostClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# AdaBoost모델생성\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m Ada_model \u001b[38;5;241m=\u001b[39m AdaBoostClassifier()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AdaBoostClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "Ada_model = AdaBoostClassifier()\n",
    "lgbm_model = LGBMClassifier()\n",
    "cb_model = CatBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ab05ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ada_param_grid = {    \n",
    "    'n_estimators' : [50,150,250],\n",
    "    'learning_rate' : [0.5,1]\n",
    "}\n",
    "grid = GridSearchCV(Ada_model,\n",
    "                    Ada_param_grid,\n",
    "                    cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5bb1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# 그리드서치 바탕으로 하이퍼파라미터 조정\n",
    "Ada_model = AdaBoostClassifier()\n",
    "final_Ada_model.fit(X_train,y_train)\n",
    "pre = final_Ada_model.predict(X_test)\n",
    "# 정답제출\n",
    "result = pd.read_csv('data/sample_submission.csv')\n",
    "result['income'] = pre\n",
    "result.to_csv('final_ada_model.csv', index = False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00727ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"final_lgbm_model = LGBMClassifier()\n",
    "final_lgbm_model.fit(X_train, y_train)\n",
    "pre = final_lgbm_model.predict(X_test)\n",
    "# 정답제출\n",
    "result = pd.read_csv('data/sample_submission.csv')\n",
    "result['income'] = pre\n",
    "result.to_csv('final_lgbm_model.csv', index = False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284f98cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"final_cb_model = CatBoostClassifier()\n",
    "final_cb_model.fit(X_train, y_train)\n",
    "pre = final_cb_model.predict(X_test)\n",
    "# 정답제출\n",
    "result = pd.read_csv('data/sample_submission.csv')\n",
    "result['income'] = pre\n",
    "result.to_csv('final_cb_model.csv', index = False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d758f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 5636, number of negative: 17808\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000749 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 340\n",
      "[LightGBM] [Info] Number of data points in the train set: 23444, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240403 -> initscore=-1.150473\n",
      "[LightGBM] [Info] Start training from score -1.150473\n",
      "Learning rate set to 0.039622\n",
      "0:\tlearn: 0.6535233\ttotal: 5.24ms\tremaining: 5.24s\n",
      "200:\tlearn: 0.2866496\ttotal: 906ms\tremaining: 3.6s\n",
      "400:\tlearn: 0.2692787\ttotal: 1.72s\tremaining: 2.56s\n",
      "600:\tlearn: 0.2596979\ttotal: 2.53s\tremaining: 1.68s\n",
      "800:\tlearn: 0.2531792\ttotal: 3.35s\tremaining: 832ms\n",
      "999:\tlearn: 0.2480846\ttotal: 4.16s\tremaining: 0us\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 5636, number of negative: 17808\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 23444, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240403 -> initscore=-1.150473\n",
      "[LightGBM] [Info] Start training from score -1.150473\n",
      "Learning rate set to 0.039622\n",
      "0:\tlearn: 0.6547496\ttotal: 5.33ms\tremaining: 5.32s\n",
      "200:\tlearn: 0.2922605\ttotal: 853ms\tremaining: 3.39s\n",
      "400:\tlearn: 0.2746913\ttotal: 1.72s\tremaining: 2.56s\n",
      "600:\tlearn: 0.2653492\ttotal: 2.51s\tremaining: 1.67s\n",
      "800:\tlearn: 0.2590310\ttotal: 3.33s\tremaining: 827ms\n",
      "999:\tlearn: 0.2540211\ttotal: 4.12s\tremaining: 0us\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 5636, number of negative: 17808\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 23444, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240403 -> initscore=-1.150473\n",
      "[LightGBM] [Info] Start training from score -1.150473\n",
      "Learning rate set to 0.039622\n",
      "0:\tlearn: 0.6545572\ttotal: 4.73ms\tremaining: 4.72s\n",
      "200:\tlearn: 0.2887860\ttotal: 846ms\tremaining: 3.36s\n",
      "400:\tlearn: 0.2721197\ttotal: 1.72s\tremaining: 2.56s\n",
      "600:\tlearn: 0.2627770\ttotal: 2.52s\tremaining: 1.67s\n",
      "800:\tlearn: 0.2558051\ttotal: 3.38s\tremaining: 841ms\n",
      "999:\tlearn: 0.2504169\ttotal: 4.23s\tremaining: 0us\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 5636, number of negative: 17808\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000724 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 23444, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240403 -> initscore=-1.150473\n",
      "[LightGBM] [Info] Start training from score -1.150473\n",
      "Learning rate set to 0.039622\n",
      "0:\tlearn: 0.6542799\ttotal: 4.81ms\tremaining: 4.81s\n",
      "200:\tlearn: 0.2877871\ttotal: 822ms\tremaining: 3.27s\n",
      "400:\tlearn: 0.2708093\ttotal: 1.69s\tremaining: 2.52s\n",
      "600:\tlearn: 0.2614617\ttotal: 2.52s\tremaining: 1.67s\n",
      "800:\tlearn: 0.2547642\ttotal: 3.33s\tremaining: 828ms\n",
      "999:\tlearn: 0.2494765\ttotal: 4.15s\tremaining: 0us\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 5636, number of negative: 17808\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000665 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 337\n",
      "[LightGBM] [Info] Number of data points in the train set: 23444, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240403 -> initscore=-1.150473\n",
      "[LightGBM] [Info] Start training from score -1.150473\n",
      "Learning rate set to 0.039622\n",
      "0:\tlearn: 0.6536622\ttotal: 5.13ms\tremaining: 5.13s\n",
      "200:\tlearn: 0.2871899\ttotal: 833ms\tremaining: 3.31s\n",
      "400:\tlearn: 0.2713859\ttotal: 1.64s\tremaining: 2.46s\n",
      "600:\tlearn: 0.2622171\ttotal: 2.48s\tremaining: 1.64s\n",
      "800:\tlearn: 0.2555478\ttotal: 3.27s\tremaining: 812ms\n",
      "999:\tlearn: 0.2503516\ttotal: 4.12s\tremaining: 0us\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 7045, number of negative: 22260\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000905 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 353\n",
      "[LightGBM] [Info] Number of data points in the train set: 29305, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240403 -> initscore=-1.150473\n",
      "[LightGBM] [Info] Start training from score -1.150473\n",
      "Learning rate set to 0.043583\n",
      "0:\tlearn: 0.6503925\ttotal: 5.61ms\tremaining: 5.6s\n",
      "200:\tlearn: 0.2867100\ttotal: 950ms\tremaining: 3.77s\n",
      "400:\tlearn: 0.2717241\ttotal: 1.94s\tremaining: 2.89s\n",
      "600:\tlearn: 0.2632925\ttotal: 2.9s\tremaining: 1.92s\n",
      "800:\tlearn: 0.2576700\ttotal: 3.88s\tremaining: 965ms\n",
      "999:\tlearn: 0.2530225\ttotal: 4.85s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "\"\"\"final_voting_model = VotingClassifier(\n",
    "                        estimators=[\n",
    "                        ('final_Ada_mode',final_Ada_model),\n",
    "                        ('final_lgbm_model',final_lgbm_model),\n",
    "                        ('final_cb_model',final_cb_model)\n",
    "                        ],\n",
    "                        voting='soft'\n",
    "                        )\n",
    "# 학습\n",
    "final_voting_model.fit(X_train,y_train)\n",
    "# 예측\n",
    "pre = final_voting_model.predict(X_test)\n",
    "# 정답제출\n",
    "result = pd.read_csv('data/sample_submission.csv')\n",
    "result['income'] = pre\n",
    "result.to_csv('final_voting_model.csv', index = False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ae98d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1185cab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
