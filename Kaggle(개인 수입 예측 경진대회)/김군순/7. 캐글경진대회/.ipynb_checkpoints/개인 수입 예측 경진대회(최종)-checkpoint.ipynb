{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "067c0322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 라이브러리 불러오기\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 시각화 전 기본 세팅\n",
    "#한글 깨짐\n",
    "plt.rc(\"font\", family=\"Malgun Gothic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b178864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 불러오기\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv', index_col='no')\n",
    "test = pd.read_csv('data/test.csv', index_col='no')\n",
    "train = pd.read_csv('data/train.csv', index_col='no')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea978e4",
   "metadata": {},
   "source": [
    "## 예측할 값 : 개인 소득\n",
    "- income : 50K 초과는 1, 50K 이하는 0 (소득)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc66511",
   "metadata": {},
   "source": [
    "### 컬럼 의미\n",
    "- age - continuous.\n",
    "- workclass(일 유형) : Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "- fnlwgt(일련의 관측 결과를 바탕으로 인구조사국이 부여하는 개인의 가중치): continuous.\n",
    "- education(교육수준) : Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "- education-num(교육수준 번호) : continuous.\n",
    "- marital-status(결혼 상태) : Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "- occupation(직업) : Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "- relationship(가족관계) : Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "- race(인종) : White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "- sex(성별) : Female, Male.\n",
    "- capital-gain(자본 이익) : continuous.\n",
    "- capital-loss(자본 손실) : continuous.\n",
    "- hours-per-week(주당 근무 시간) : continuous.\n",
    "- native-country(국적) : United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee20e888",
   "metadata": {},
   "source": [
    "### value값 띄어쓰기 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f264a463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 띄어쓰기 제거함\n",
    "for i in train.columns : \n",
    "    if train[f'{i}'].dtype == 'object' :\n",
    "        train[f'{i}'] = train[f'{i}'].apply(lambda x: x.replace(' ', '')) # 제거하는 함수\n",
    "    else :\n",
    "        train[f'{i}'] = train[f'{i}']\n",
    "        \n",
    "for i in test.columns : \n",
    "    if test[f'{i}'].dtype == 'object' :\n",
    "        test[f'{i}'] = test[f'{i}'].apply(lambda x: x.replace(' ', '')) # 제거하는 함수\n",
    "    else :\n",
    "        test[f'{i}'] = test[f'{i}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91cb8e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=['Private', 'Self-emp-not-inc', 'Local-gov', '?',\n",
    "       'State-gov', 'Self-emp-inc','Federal-gov','Without-pay','Never-worked']\n",
    "cover_title=['Private', 'Self-emp-not-inc', 'Local-gov', 'Never-worked',\n",
    "       'State-gov', 'Self-emp-inc','Federal-gov','Without-pay','Never-worked']\n",
    "title_dict = dict(zip(title, cover_title))\n",
    "title_dict\n",
    "train['workclass'] = train['workclass'].map(title_dict)\n",
    "test['workclass'] =test['workclass'].map(title_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88bd1491",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=['United-States', 'Haiti', 'Mexico', 'Puerto-Rico', 'Philippines',\n",
    "       '?', 'Germany', 'Peru', 'Ecuador', 'Iran', 'Thailand',\n",
    "       'Dominican-Republic', 'Poland', 'Scotland', 'Italy', 'Jamaica',\n",
    "       'China', 'Portugal', 'Columbia', 'Hungary', 'Vietnam', 'Taiwan',\n",
    "       'Canada', 'Hong', 'Guatemala', 'El-Salvador', 'England',\n",
    "       'Outlying-US(Guam-USVI-etc)', 'India', 'France', 'Cuba', 'Greece',\n",
    "       'Trinadad&Tobago', 'South', 'Japan', 'Yugoslavia', 'Nicaragua',\n",
    "       'Ireland', 'Cambodia', 'Laos', 'Honduras', 'Holand-Netherlands']\n",
    "cover_title=['United-States', 'Haiti', 'Mexico', 'Puerto-Rico', 'Philippines',\n",
    "       'United-States', 'Germany', 'Peru', 'Ecuador', 'Iran', 'Thailand',\n",
    "       'Dominican-Republic', 'Poland', 'Scotland', 'Italy', 'Jamaica',\n",
    "       'China', 'Portugal', 'Columbia', 'Hungary', 'Vietnam', 'Taiwan',\n",
    "       'Canada', 'Hong', 'Guatemala', 'El-Salvador', 'England',\n",
    "       'Outlying-US(Guam-USVI-etc)', 'India', 'France', 'Cuba', 'Greece',\n",
    "       'Trinadad&Tobago', 'South', 'Japan', 'Yugoslavia', 'Nicaragua',\n",
    "       'Ireland', 'Cambodia', 'Laos', 'Honduras', 'Holand-Netherlands']\n",
    "title_dict = dict(zip(title, cover_title))\n",
    "title_dict\n",
    "train['native-country'] = train['native-country'].map(title_dict)\n",
    "\n",
    "test['native-country'] = test['native-country'].map(title_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69e1fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=['Machine-op-inspct', 'Other-service', 'Handlers-cleaners',\n",
    "       'Tech-support', 'Transport-moving', 'Farming-fishing',\n",
    "       'Prof-specialty', 'Priv-house-serv', 'Adm-clerical',\n",
    "       'Protective-serv', 'Exec-managerial', '?', 'Craft-repair', 'Sales',\n",
    "       'Armed-Forces']\n",
    "cover_title=['Machine-op-inspct', 'Other-service', 'Handlers-cleaners',\n",
    "       'Tech-support', 'Transport-moving', 'Farming-fishing',\n",
    "       'Prof-specialty', 'Priv-house-serv', 'Adm-clerical',\n",
    "       'Protective-serv', 'Exec-managerial', '?', 'Craft-repair', 'Sales',\n",
    "       'Armed-Forces']\n",
    "title_dict = dict(zip(title, cover_title))\n",
    "title_dict\n",
    "train['occupation'] = train['occupation'].map(title_dict)\n",
    "test['occupation'] = test['occupation'].map(title_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d23ee4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('education',axis=1)\n",
    "test = test.drop('education',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b222557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "marital_status = ['Divorced', 'Never-married', 'Married-civ-spouse', 'Separated',\n",
    "       'Married-spouse-absent', 'Widowed', 'Married-AF-spouse']\n",
    "conver_marital_status = ['not-married', 'not-married', 'married', 'not-married', 'not-married', 'not-married','married']\n",
    "marital_status_dict=dict(zip(marital_status, conver_marital_status))\n",
    "\n",
    "train['marital-status']=train['marital-status'].map(marital_status_dict)\n",
    "test['marital-status']=test['marital-status'].map(marital_status_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ac87835",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['relationship'].unique()\n",
    "title=['Not-in-family', 'Husband', 'Unmarried', 'Other-relative',\n",
    "       'Own-child', 'Wife']\n",
    "cover_title=['Not-in-family', 'Married', 'Unmarried', 'Other-relative',\n",
    "       'Own-child', 'Married']\n",
    "title_dict = dict(zip(title, cover_title))\n",
    "train['relationship'] = train['relationship'].map(title_dict)\n",
    "\n",
    "title=['Own-child', 'Wife', 'Husband', 'Not-in-family', 'Unmarried',\n",
    "       'Other-relative']\n",
    "cover_title=['Own-child', 'Married', 'Married', 'Not-in-family', 'Unmarried',\n",
    "       'Other-relative']\n",
    "title_dict = dict(zip(title, cover_title))\n",
    "test['relationship'] = test['relationship'].map(title_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71651442",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0,4,8,12,16] # 범위지정\n",
    "labels = ['e1', 'e2', 'e3', 'e4'] # 라벨지정\n",
    "train['education-num'] = pd.cut(train['education-num'], bins=bins, labels = labels)\n",
    "test['education-num'] = pd.cut(test['education-num'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b76a6fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [i for i in range(0, 101,10)]\n",
    "labels = ['age' + str(i) for i in range(0, 100,10)] # 라벨지정\n",
    "train['age'] = pd.cut(train['age'], bins=bins, labels = labels)\n",
    "test['age'] = pd.cut(test['age'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28bd38d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=['Private', 'Self-emp-not-inc', 'Local-gov', 'State-gov',\n",
    "       'Self-emp-inc', 'Federal-gov', 'Without-pay', 'Never-worked']\n",
    "cover_title=['Private', 'Self-emp', 'gov', 'gov',\n",
    "       'Self-emp', 'gov', 'beggar', 'beggar']\n",
    "title_dict = dict(zip(title, cover_title))\n",
    "train['workclass'] = train['workclass'].map(title_dict)\n",
    "test['workclass'] = test['workclass'].map(title_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45470ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "native_country = ['United-States', 'Haiti', 'Mexico', 'Puerto-Rico', 'Philippines',\n",
    "       'Germany', 'Peru', 'Ecuador', 'Iran', 'Thailand',\n",
    "       'Dominican-Republic', 'Poland', 'Scotland', 'Italy', 'Jamaica',\n",
    "       'China', 'Columbia', 'Hungary', 'Portugal', 'Vietnam', 'Taiwan',\n",
    "       'Canada', 'Hong', 'Guatemala', 'El-Salvador', 'England',\n",
    "       'Outlying-US(Guam-USVI-etc)', 'India', 'France', 'Cuba', 'Greece',\n",
    "       'Trinadad&Tobago', 'South', 'Japan', 'Yugoslavia', 'Nicaragua',\n",
    "       'Ireland', 'Cambodia', 'Laos', 'Honduras', 'Holand-Netherlands']\n",
    "conver_native_country = ['United-State', 'North-America', 'North-America', 'North-America', 'Asia',\n",
    "                        'Europe', 'South-America', 'South-America', 'Asia', 'Asia',\n",
    "                        'North-America', 'Europe', 'Europe', 'Europe', 'North-America',\n",
    "                        'Asia', 'South-America', 'Europe', 'Europe', 'Asia', 'Asia',\n",
    "                        'North-America', 'Asia', 'North-America', 'North-America', 'Europe',\n",
    "                        'North-America', 'Asia', 'Europe', 'North-America', 'Europe',\n",
    "                        'South-America', 'Asia', 'Asia', 'Europe', 'North-America',\n",
    "                        'Europe', 'Asia', 'Asia', 'North-America', 'Europe']\n",
    "\n",
    "native_country_dict = dict(zip(native_country, conver_native_country))\n",
    "native_country_dict\n",
    "train['native-country']=train['native-country'].map(native_country_dict)\n",
    "test['native-country']=test['native-country'].map(native_country_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c91a258d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United-State     26796\n",
       "North-America     1282\n",
       "Asia               657\n",
       "Europe             458\n",
       "South-America      112\n",
       "Name: native-country, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['native-country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c18e6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('fnlwgt',axis=1)\n",
    "test= test.drop('fnlwgt',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b59a913",
   "metadata": {},
   "source": [
    "- 컬럼순서 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85f163ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제/답 분리\n",
    "X_train = train.loc[:,:'native-country']\n",
    "y_train = train['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6443dbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train) # 0과 1로만 이루어진 열을 생성\n",
    "X_test = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cf22ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler =StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "st_transform_X_train =scaler.transform(X_train)\n",
    "X_train = pd.DataFrame(st_transform_X_train, columns=X_train.columns)\n",
    "st_transform_X_test =scaler.transform(X_test)\n",
    "X_test = pd.DataFrame(st_transform_X_test, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de9f2720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd924bbd",
   "metadata": {},
   "source": [
    "그리드 서치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9ddf70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ada_model = AdaBoostClassifier()\\nAda_param_grid = {    \\n    'n_estimators' : [50,150,250],\\n    'learning_rate' : [0.5,1]\\n}\\nAda_grid = GridSearchCV(Ada_model,\\n                        Ada_param_grid,\\n                        cv = 3)\\nAda_grid.fit(X_train,y_train)\\n# best_score_ 메서드\\nprint(Ada_grid.best_score_)\\n# best_params_ 메서드\\nprint(Ada_grid.best_params_)\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Ada_model = AdaBoostClassifier()\n",
    "Ada_param_grid = {    \n",
    "    'n_estimators' : [50,150,250],\n",
    "    'learning_rate' : [0.5,1]\n",
    "}\n",
    "Ada_grid = GridSearchCV(Ada_model,\n",
    "                        Ada_param_grid,\n",
    "                        cv = 3)\n",
    "Ada_grid.fit(X_train,y_train)\n",
    "# best_score_ 메서드\n",
    "print(Ada_grid.best_score_)\n",
    "# best_params_ 메서드\n",
    "print(Ada_grid.best_params_)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12803ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"lgbm = LGBMClassifier()\\n\\nparams = {\\n    'boosting_type': ['gbdt', 'dart'], # defalt 'gbdt'\\n    'num_leaves': [20, 31, 50, 70], # default 31\\n    'max_depth': [-1, 5, 7, 10, 15, 20, 30], # default -1. 끝까지 만드는 것\\n    'learning_rate': [0.001, 0.01, 0.05, 0.1], # defaut 0.1\\n}\\n\\nlgbm_grid_cv = GridSearchCV(lgbm, param_grid=params, scoring='f1', n_jobs=-1, cv=5, verbose=1)\\nlgbm_grid_cv.fit(X_train,y_train)\\nprint('GridSearchCV 최고 평균 정확도 수치: {:.4f}'.format(lgbm_grid_cv.best_score_))\\nprint('GridSearchCv 최적 하이퍼 파라미터: ', lgbm_grid_cv.best_params_)\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"lgbm = LGBMClassifier()\n",
    "\n",
    "params = {\n",
    "    'boosting_type': ['gbdt', 'dart'], # defalt 'gbdt'\n",
    "    'num_leaves': [20, 31, 50, 70], # default 31\n",
    "    'max_depth': [-1, 5, 7, 10, 15, 20, 30], # default -1. 끝까지 만드는 것\n",
    "    'learning_rate': [0.001, 0.01, 0.05, 0.1], # defaut 0.1\n",
    "}\n",
    "\n",
    "lgbm_grid_cv = GridSearchCV(lgbm, param_grid=params, scoring='f1', n_jobs=-1, cv=5, verbose=1)\n",
    "lgbm_grid_cv.fit(X_train,y_train)\n",
    "print('GridSearchCV 최고 평균 정확도 수치: {:.4f}'.format(lgbm_grid_cv.best_score_))\n",
    "print('GridSearchCv 최적 하이퍼 파라미터: ', lgbm_grid_cv.best_params_)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c77fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f9bc85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그리드서치 바탕으로 하이퍼파라미터 조정\n",
    "final_Ada_model = AdaBoostClassifier(learning_rate= 1,\n",
    "                                    n_estimators = 250)\n",
    "final_Ada_model.fit(X_train,y_train)\n",
    "pre = final_Ada_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5be5b7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8632655294161077"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = cross_val_score(final_Ada_model,\n",
    "                          X_train,\n",
    "                          y_train,\n",
    "                          cv = 3)\n",
    "result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c224e40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7045, number of negative: 22260\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 406\n",
      "[LightGBM] [Info] Number of data points in the train set: 29305, number of used features: 52\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240403 -> initscore=-1.150473\n",
      "[LightGBM] [Info] Start training from score -1.150473\n"
     ]
    }
   ],
   "source": [
    "final_lgbm_model = LGBMClassifier(learning_rate=0.01,\n",
    "                                 max_depth = 50,\n",
    "                                 n_estimators=800,\n",
    "                                 num_leaves=100)\n",
    "final_lgbm_model.fit(X_train, y_train)\n",
    "pre = final_lgbm_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ef2ea57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4696, number of negative: 14840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 383\n",
      "[LightGBM] [Info] Number of data points in the train set: 19536, number of used features: 52\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240377 -> initscore=-1.150615\n",
      "[LightGBM] [Info] Start training from score -1.150615\n",
      "[LightGBM] [Info] Number of positive: 4697, number of negative: 14840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 385\n",
      "[LightGBM] [Info] Number of data points in the train set: 19537, number of used features: 52\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240416 -> initscore=-1.150402\n",
      "[LightGBM] [Info] Start training from score -1.150402\n",
      "[LightGBM] [Info] Number of positive: 4697, number of negative: 14840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 19537, number of used features: 52\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240416 -> initscore=-1.150402\n",
      "[LightGBM] [Info] Start training from score -1.150402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8665414733077749"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = cross_val_score(final_lgbm_model,\n",
    "                          X_train,\n",
    "                          y_train,\n",
    "                          cv = 3)\n",
    "result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88dfff24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.043583\n",
      "0:\tlearn: 0.6522390\ttotal: 151ms\tremaining: 2m 30s\n",
      "100:\tlearn: 0.3008148\ttotal: 826ms\tremaining: 7.35s\n",
      "200:\tlearn: 0.2868144\ttotal: 1.51s\tremaining: 5.99s\n",
      "300:\tlearn: 0.2775283\ttotal: 2.14s\tremaining: 4.98s\n",
      "400:\tlearn: 0.2713824\ttotal: 2.81s\tremaining: 4.2s\n",
      "500:\tlearn: 0.2665143\ttotal: 3.49s\tremaining: 3.47s\n",
      "600:\tlearn: 0.2630183\ttotal: 4.09s\tremaining: 2.71s\n",
      "700:\tlearn: 0.2599216\ttotal: 4.73s\tremaining: 2.02s\n",
      "800:\tlearn: 0.2573804\ttotal: 5.39s\tremaining: 1.34s\n",
      "900:\tlearn: 0.2550161\ttotal: 5.99s\tremaining: 659ms\n",
      "999:\tlearn: 0.2529742\ttotal: 6.62s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "final_cb_model = CatBoostClassifier(verbose=100)\n",
    "final_cb_model.fit(X_train, y_train)\n",
    "pre = final_cb_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0799515f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.036654\n",
      "0:\tlearn: 0.6589134\ttotal: 6.24ms\tremaining: 6.23s\n",
      "100:\tlearn: 0.3057233\ttotal: 631ms\tremaining: 5.62s\n",
      "200:\tlearn: 0.2895545\ttotal: 1.2s\tremaining: 4.77s\n",
      "300:\tlearn: 0.2800214\ttotal: 1.75s\tremaining: 4.05s\n",
      "400:\tlearn: 0.2722119\ttotal: 2.33s\tremaining: 3.48s\n",
      "500:\tlearn: 0.2662914\ttotal: 2.88s\tremaining: 2.86s\n",
      "600:\tlearn: 0.2618951\ttotal: 3.4s\tremaining: 2.25s\n",
      "700:\tlearn: 0.2581286\ttotal: 3.96s\tremaining: 1.69s\n",
      "800:\tlearn: 0.2545490\ttotal: 4.51s\tremaining: 1.12s\n",
      "900:\tlearn: 0.2520486\ttotal: 5.07s\tremaining: 557ms\n",
      "999:\tlearn: 0.2491248\ttotal: 5.61s\tremaining: 0us\n",
      "Learning rate set to 0.036655\n",
      "0:\tlearn: 0.6590239\ttotal: 6.12ms\tremaining: 6.12s\n",
      "100:\tlearn: 0.3077846\ttotal: 617ms\tremaining: 5.49s\n",
      "200:\tlearn: 0.2927916\ttotal: 1.16s\tremaining: 4.62s\n",
      "300:\tlearn: 0.2830286\ttotal: 1.73s\tremaining: 4.01s\n",
      "400:\tlearn: 0.2752660\ttotal: 2.32s\tremaining: 3.46s\n",
      "500:\tlearn: 0.2693930\ttotal: 2.89s\tremaining: 2.87s\n",
      "600:\tlearn: 0.2653049\ttotal: 3.44s\tremaining: 2.28s\n",
      "700:\tlearn: 0.2612342\ttotal: 3.98s\tremaining: 1.7s\n",
      "800:\tlearn: 0.2577855\ttotal: 4.55s\tremaining: 1.13s\n",
      "900:\tlearn: 0.2548585\ttotal: 5.15s\tremaining: 566ms\n",
      "999:\tlearn: 0.2519623\ttotal: 5.7s\tremaining: 0us\n",
      "Learning rate set to 0.036655\n",
      "0:\tlearn: 0.6580381\ttotal: 5.66ms\tremaining: 5.65s\n",
      "100:\tlearn: 0.3011831\ttotal: 607ms\tremaining: 5.4s\n",
      "200:\tlearn: 0.2856040\ttotal: 1.15s\tremaining: 4.55s\n",
      "300:\tlearn: 0.2759215\ttotal: 1.69s\tremaining: 3.93s\n",
      "400:\tlearn: 0.2687528\ttotal: 2.29s\tremaining: 3.41s\n",
      "500:\tlearn: 0.2633424\ttotal: 2.85s\tremaining: 2.84s\n",
      "600:\tlearn: 0.2591881\ttotal: 3.4s\tremaining: 2.26s\n",
      "700:\tlearn: 0.2556539\ttotal: 3.93s\tremaining: 1.68s\n",
      "800:\tlearn: 0.2521041\ttotal: 4.53s\tremaining: 1.12s\n",
      "900:\tlearn: 0.2491713\ttotal: 5.06s\tremaining: 556ms\n",
      "999:\tlearn: 0.2466976\ttotal: 5.6s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.866916831217169"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = cross_val_score(final_cb_model,\n",
    "                          X_train,\n",
    "                          y_train,\n",
    "                          cv = 3)\n",
    "result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d758f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7045, number of negative: 22260\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004064 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 406\n",
      "[LightGBM] [Info] Number of data points in the train set: 29305, number of used features: 52\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240403 -> initscore=-1.150473\n",
      "[LightGBM] [Info] Start training from score -1.150473\n",
      "Learning rate set to 0.043583\n",
      "0:\tlearn: 0.6522390\ttotal: 6.92ms\tremaining: 6.91s\n",
      "100:\tlearn: 0.3008148\ttotal: 658ms\tremaining: 5.85s\n",
      "200:\tlearn: 0.2868144\ttotal: 1.37s\tremaining: 5.46s\n",
      "300:\tlearn: 0.2775283\ttotal: 2.03s\tremaining: 4.71s\n",
      "400:\tlearn: 0.2713824\ttotal: 2.68s\tremaining: 4s\n",
      "500:\tlearn: 0.2665143\ttotal: 3.38s\tremaining: 3.37s\n",
      "600:\tlearn: 0.2630183\ttotal: 4.04s\tremaining: 2.68s\n",
      "700:\tlearn: 0.2599216\ttotal: 4.66s\tremaining: 1.99s\n",
      "800:\tlearn: 0.2573804\ttotal: 5.38s\tremaining: 1.33s\n",
      "900:\tlearn: 0.2550161\ttotal: 6.03s\tremaining: 663ms\n",
      "999:\tlearn: 0.2529742\ttotal: 6.68s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "final_voting_model = VotingClassifier(\n",
    "                        estimators=[\n",
    "                            ('final_Ada_model',final_Ada_model),\n",
    "                            ('final_lgbm_model',final_lgbm_model),\n",
    "                            ('final_cb_model',final_cb_model)\n",
    "                        ],\n",
    "                        voting='soft'\n",
    "                        )\n",
    "# 학습\n",
    "final_voting_model.fit(X_train,y_train)\n",
    "# 예측\n",
    "pre = final_voting_model.predict(X_test)\n",
    "# 정답제출\n",
    "result = pd.read_csv('data/sample_submission.csv')\n",
    "result['income'] = pre\n",
    "result.to_csv('final_voting_model82.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98ae98d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4696, number of negative: 14840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 383\n",
      "[LightGBM] [Info] Number of data points in the train set: 19536, number of used features: 52\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240377 -> initscore=-1.150615\n",
      "[LightGBM] [Info] Start training from score -1.150615\n",
      "Learning rate set to 0.036654\n",
      "0:\tlearn: 0.6589134\ttotal: 7.06ms\tremaining: 7.05s\n",
      "100:\tlearn: 0.3057233\ttotal: 663ms\tremaining: 5.9s\n",
      "200:\tlearn: 0.2895545\ttotal: 1.32s\tremaining: 5.25s\n",
      "300:\tlearn: 0.2800214\ttotal: 1.92s\tremaining: 4.45s\n",
      "400:\tlearn: 0.2722119\ttotal: 2.47s\tremaining: 3.69s\n",
      "500:\tlearn: 0.2662914\ttotal: 3.02s\tremaining: 3.01s\n",
      "600:\tlearn: 0.2618951\ttotal: 3.65s\tremaining: 2.42s\n",
      "700:\tlearn: 0.2581286\ttotal: 4.25s\tremaining: 1.81s\n",
      "800:\tlearn: 0.2545490\ttotal: 4.8s\tremaining: 1.19s\n",
      "900:\tlearn: 0.2520486\ttotal: 5.39s\tremaining: 592ms\n",
      "999:\tlearn: 0.2491248\ttotal: 5.95s\tremaining: 0us\n",
      "[LightGBM] [Info] Number of positive: 4697, number of negative: 14840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 385\n",
      "[LightGBM] [Info] Number of data points in the train set: 19537, number of used features: 52\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240416 -> initscore=-1.150402\n",
      "[LightGBM] [Info] Start training from score -1.150402\n",
      "Learning rate set to 0.036655\n",
      "0:\tlearn: 0.6590239\ttotal: 6.55ms\tremaining: 6.54s\n",
      "100:\tlearn: 0.3077846\ttotal: 593ms\tremaining: 5.28s\n",
      "200:\tlearn: 0.2927916\ttotal: 1.27s\tremaining: 5.05s\n",
      "300:\tlearn: 0.2830286\ttotal: 1.87s\tremaining: 4.34s\n",
      "400:\tlearn: 0.2752660\ttotal: 2.42s\tremaining: 3.62s\n",
      "500:\tlearn: 0.2693930\ttotal: 3.04s\tremaining: 3.03s\n",
      "600:\tlearn: 0.2653049\ttotal: 3.66s\tremaining: 2.43s\n",
      "700:\tlearn: 0.2612342\ttotal: 4.27s\tremaining: 1.82s\n",
      "800:\tlearn: 0.2577855\ttotal: 4.87s\tremaining: 1.21s\n",
      "900:\tlearn: 0.2548585\ttotal: 5.51s\tremaining: 605ms\n",
      "999:\tlearn: 0.2519623\ttotal: 6.08s\tremaining: 0us\n",
      "[LightGBM] [Info] Number of positive: 4697, number of negative: 14840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 19537, number of used features: 52\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240416 -> initscore=-1.150402\n",
      "[LightGBM] [Info] Start training from score -1.150402\n",
      "Learning rate set to 0.036655\n",
      "0:\tlearn: 0.6580381\ttotal: 7.52ms\tremaining: 7.51s\n",
      "100:\tlearn: 0.3011831\ttotal: 640ms\tremaining: 5.7s\n",
      "200:\tlearn: 0.2856040\ttotal: 1.23s\tremaining: 4.88s\n",
      "300:\tlearn: 0.2759215\ttotal: 1.83s\tremaining: 4.25s\n",
      "400:\tlearn: 0.2687528\ttotal: 2.41s\tremaining: 3.6s\n",
      "500:\tlearn: 0.2633424\ttotal: 3.05s\tremaining: 3.04s\n",
      "600:\tlearn: 0.2591881\ttotal: 3.6s\tremaining: 2.39s\n",
      "700:\tlearn: 0.2556539\ttotal: 4.16s\tremaining: 1.77s\n",
      "800:\tlearn: 0.2521041\ttotal: 4.78s\tremaining: 1.19s\n",
      "900:\tlearn: 0.2491713\ttotal: 5.35s\tremaining: 588ms\n",
      "999:\tlearn: 0.2466976\ttotal: 5.89s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8670191713875816"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = cross_val_score(final_voting_model,\n",
    "                          X_train,\n",
    "                          y_train,\n",
    "                          cv = 3)\n",
    "result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88edeee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
