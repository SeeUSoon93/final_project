{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "067c0322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 라이브러리 불러오기\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#한글 깨짐\n",
    "plt.rc(\"font\", family=\"Malgun Gothic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "b178864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 불러오기\n",
    "test = pd.read_csv('data/test.csv', index_col='no')\n",
    "train = pd.read_csv('data/train.csv', index_col='no')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea978e4",
   "metadata": {},
   "source": [
    "## 예측할 값 : 개인 소득\n",
    "- income : 50K 초과는 1, 50K 이하는 0 (소득)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc66511",
   "metadata": {},
   "source": [
    "### 컬럼 의미\n",
    "- age - continuous.\n",
    "- workclass(일 유형) : Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "- fnlwgt(일련의 관측 결과를 바탕으로 인구조사국이 부여하는 개인의 가중치): continuous.\n",
    "- education(교육수준) : Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "- education-num(교육수준 번호) : continuous.\n",
    "- marital-status(결혼 상태) : Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "- occupation(직업) : Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "- relationship(가족관계) : Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "- race(인종) : White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "- sex(성별) : Female, Male.\n",
    "- capital-gain(자본 이익) : continuous.\n",
    "- capital-loss(자본 손실) : continuous.\n",
    "- hours-per-week(주당 근무 시간) : continuous.\n",
    "- native-country(국적) : United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee20e888",
   "metadata": {},
   "source": [
    "### value값 띄어쓰기 제거\n",
    "- value_counts()로 찍어보니 뭔가 이상하다\n",
    "- 앞에 띄어쓰기가 있네? 띄어쓰기 없애준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "f264a463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda 함수\n",
    "# lambda 매개변수 : 표현식\n",
    "for i in train.columns : \n",
    "    if train[f'{i}'].dtype == 'object' :\n",
    "        train[f'{i}'] = train[f'{i}'].apply(lambda x: x.replace(' ', ''))\n",
    "    else :\n",
    "        train[f'{i}'] = train[f'{i}']\n",
    "        \n",
    "for i in test.columns : \n",
    "    if test[f'{i}'].dtype == 'object' :\n",
    "        test[f'{i}'] = test[f'{i}'].apply(lambda x: x.replace(' ', ''))\n",
    "    else :\n",
    "        test[f'{i}'] = test[f'{i}']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0eeeb9",
   "metadata": {},
   "source": [
    "### ? 채우기\n",
    "- ?는 최빈값으로 채우는게 제일 낫다고 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "0ebc1770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prof-specialty       3724\n",
       "Craft-repair         3632\n",
       "Exec-managerial      3609\n",
       "Adm-clerical         3440\n",
       "Sales                3292\n",
       "Other-service        2975\n",
       "Machine-op-inspct    1811\n",
       "?                    1668\n",
       "Transport-moving     1393\n",
       "Handlers-cleaners    1249\n",
       "Farming-fishing       888\n",
       "Tech-support          865\n",
       "Protective-serv       603\n",
       "Priv-house-serv       146\n",
       "Armed-Forces           10\n",
       "Name: occupation, dtype: int64"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "4bb285ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workclass에서 ?인 애들은 occupation에서도 ? 냐? True\n"
     ]
    }
   ],
   "source": [
    "work_occ = train[(train['workclass'] == '?') & (train['occupation'] == '?')].shape[0]\n",
    "work = train[train['workclass'] == '?'].shape[0]\n",
    "print(\"workclass에서 ?인 애들은 occupation에서도 ? 냐?\",work_occ == work)\n",
    "\n",
    "# 일 안하니까 쪽팔려서 안적은거 아니야?\n",
    "# workclass는 Never-worked로 바꿔버림.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "591f52ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prof-specialty       3724\n",
       "Craft-repair         3632\n",
       "Exec-managerial      3609\n",
       "Adm-clerical         3440\n",
       "Sales                3292\n",
       "Other-service        2975\n",
       "Machine-op-inspct    1811\n",
       "?                    1663\n",
       "Transport-moving     1393\n",
       "Handlers-cleaners    1249\n",
       "Farming-fishing       888\n",
       "Tech-support          865\n",
       "Protective-serv       603\n",
       "Priv-house-serv       146\n",
       "Armed-Forces           10\n",
       "Name: occupation, dtype: int64"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train['workclass'] != 'Never-worked')]['occupation'].value_counts()\n",
    "#일안하는 애들은 occupation에 적을게 없네? 그럼 ? 냅둬보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "91cb8e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"title=['Private', 'Self-emp-not-inc', 'Local-gov', '?',\\n       'State-gov', 'Self-emp-inc','Federal-gov','Without-pay','Never-worked']\\ncover_title=['Private', 'Self-emp-not-inc', 'Local-gov', 'Never-worked',\\n       'State-gov', 'Self-emp-inc','Federal-gov','Without-pay','Never-worked']\\ntitle_dict = dict(zip(title, cover_title))\\ntitle_dict\\ntrain['workclass'] = train['workclass'].map(title_dict)\\ntest['workclass'] =test['workclass'].map(title_dict)\""
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title=['Private', 'Self-emp-not-inc', 'Local-gov', '?',\n",
    "       'State-gov', 'Self-emp-inc','Federal-gov','Without-pay','Never-worked']\n",
    "cover_title=['Private', 'Self-emp-not-inc', 'Local-gov', 'Never-worked',\n",
    "       'State-gov', 'Self-emp-inc','Federal-gov','Without-pay','Never-worked']\n",
    "title_dict = dict(zip(title, cover_title))\n",
    "title_dict\n",
    "train['workclass'] = train['workclass'].map(title_dict)\n",
    "test['workclass'] =test['workclass'].map(title_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "88bd1491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# native-country의 ?의 갯수는 400대로 적고 United-States의 값이 압도적으로 많기 때문에 최빈값으로 채움\n",
    "title=['United-States', 'Haiti', 'Mexico', 'Puerto-Rico', 'Philippines',\n",
    "       '?', 'Germany', 'Peru', 'Ecuador', 'Iran', 'Thailand',\n",
    "       'Dominican-Republic', 'Poland', 'Scotland', 'Italy', 'Jamaica',\n",
    "       'China', 'Portugal', 'Columbia', 'Hungary', 'Vietnam', 'Taiwan',\n",
    "       'Canada', 'Hong', 'Guatemala', 'El-Salvador', 'England',\n",
    "       'Outlying-US(Guam-USVI-etc)', 'India', 'France', 'Cuba', 'Greece',\n",
    "       'Trinadad&Tobago', 'South', 'Japan', 'Yugoslavia', 'Nicaragua',\n",
    "       'Ireland', 'Cambodia', 'Laos', 'Honduras', 'Holand-Netherlands']\n",
    "cover_title=['United-States', 'Haiti', 'Mexico', 'Puerto-Rico', 'Philippines',\n",
    "       'United-States', 'Germany', 'Peru', 'Ecuador', 'Iran', 'Thailand',\n",
    "       'Dominican-Republic', 'Poland', 'Scotland', 'Italy', 'Jamaica',\n",
    "       'China', 'Portugal', 'Columbia', 'Hungary', 'Vietnam', 'Taiwan',\n",
    "       'Canada', 'Hong', 'Guatemala', 'El-Salvador', 'England',\n",
    "       'Outlying-US(Guam-USVI-etc)', 'India', 'France', 'Cuba', 'Greece',\n",
    "       'Trinadad&Tobago', 'South', 'Japan', 'Yugoslavia', 'Nicaragua',\n",
    "       'Ireland', 'Cambodia', 'Laos', 'Honduras', 'Holand-Netherlands']\n",
    "title_dict = dict(zip(title, cover_title))\n",
    "title_dict\n",
    "train['native-country'] = train['native-country'].map(title_dict)\n",
    "\n",
    "test['native-country'] = test['native-country'].map(title_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "69e1fa92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"title=['Machine-op-inspct', 'Other-service', 'Handlers-cleaners',\\n       'Tech-support', 'Transport-moving', 'Farming-fishing',\\n       'Prof-specialty', 'Priv-house-serv', 'Adm-clerical',\\n       'Protective-serv', 'Exec-managerial', '?', 'Craft-repair', 'Sales',\\n       'Armed-Forces']\\ncover_title=['Machine-op-inspct', 'Other-service', 'Handlers-cleaners',\\n       'Tech-support', 'Transport-moving', 'Farming-fishing',\\n       'Prof-specialty', 'Priv-house-serv', 'Adm-clerical',\\n       'Protective-serv', 'Exec-managerial', '?', 'Craft-repair', 'Sales',\\n       'Armed-Forces']\\ntitle_dict = dict(zip(title, cover_title))\\ntitle_dict\\ntrain['occupation'] = train['occupation'].map(title_dict)\\ntest['occupation'] = test['occupation'].map(title_dict)\""
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title=['Machine-op-inspct', 'Other-service', 'Handlers-cleaners',\n",
    "       'Tech-support', 'Transport-moving', 'Farming-fishing',\n",
    "       'Prof-specialty', 'Priv-house-serv', 'Adm-clerical',\n",
    "       'Protective-serv', 'Exec-managerial', '?', 'Craft-repair', 'Sales',\n",
    "       'Armed-Forces']\n",
    "cover_title=['Machine-op-inspct', 'Other-service', 'Handlers-cleaners',\n",
    "       'Tech-support', 'Transport-moving', 'Farming-fishing',\n",
    "       'Prof-specialty', 'Priv-house-serv', 'Adm-clerical',\n",
    "       'Protective-serv', 'Exec-managerial', '?', 'Craft-repair', 'Sales',\n",
    "       'Armed-Forces']\n",
    "title_dict = dict(zip(title, cover_title))\n",
    "title_dict\n",
    "train['occupation'] = train['occupation'].map(title_dict)\n",
    "test['occupation'] = test['occupation'].map(title_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "d23ee4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# education과 education-num은 동일한 내용\n",
    "# education-num은 숫자라 나중에 카테고리화 하기 쉬우니 남겨두고 education을 지우기\n",
    "train = train.drop('education',axis=1)\n",
    "test = test.drop('education',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "b222557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# marital_status에서는 결혼한 상태인지 아닌지만 보면 될 것으로 판단\n",
    "marital_status = ['Divorced', 'Never-married', 'Married-civ-spouse', 'Separated',\n",
    "       'Married-spouse-absent', 'Widowed', 'Married-AF-spouse']\n",
    "conver_marital_status = ['not-married', 'not-married', 'married', 'not-married', 'not-married', 'not-married','married']\n",
    "marital_status_dict=dict(zip(marital_status, conver_marital_status))\n",
    "\n",
    "train['marital-status']=train['marital-status'].map(marital_status_dict)\n",
    "test['marital-status']=test['marital-status'].map(marital_status_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "5ac87835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# husband와 wife빼고는 큰 의미 없는 듯해서 그냥 나두고 둘은 married로 치환\n",
    "train['relationship'].unique()\n",
    "title=['Not-in-family', 'Husband', 'Unmarried', 'Other-relative',\n",
    "       'Own-child', 'Wife']\n",
    "cover_title=['Not-in-family', 'Married', 'Unmarried', 'Other-relative',\n",
    "       'Own-child', 'Married']\n",
    "title_dict = dict(zip(title, cover_title))\n",
    "train['relationship'] = train['relationship'].map(title_dict)\n",
    "test['relationship'] = test['relationship'].map(title_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "71651442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교육수준은 크게 저,중,고로 나눌 수 있는데, 중간이 많기 때문에 그냥 4분할 함\n",
    "bins = [0,4,8,12,16] # 범위지정\n",
    "labels = ['e1', 'e2', 'e3', 'e4'] # 라벨지정\n",
    "train['education-num'] = pd.cut(train['education-num'], bins=bins, labels = labels)\n",
    "test['education-num'] = pd.cut(test['education-num'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "b76a6fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나이는 처음엔 3분할 했으나 너무 크게 묶이는 거 같아 20대 별로 재분할\n",
    "bins = [i for i in range(0, 101,20)]\n",
    "labels = ['age' + str(i) for i in range(0, 100,20)] # 라벨지정\n",
    "train['age'] = pd.cut(train['age'], bins=bins, labels = labels)\n",
    "test['age'] = pd.cut(test['age'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "28bd38d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# workclass는 사기업, 사업가, 공무원, 거지로 나눔\n",
    "title=['Private', 'Self-emp-not-inc', 'Local-gov', 'State-gov',\n",
    "       'Self-emp-inc', 'Federal-gov', 'Without-pay', 'Never-worked']\n",
    "cover_title=['Private', 'Self-emp', 'gov', 'gov',\n",
    "       'Self-emp', 'gov', 'beggar', 'beggar']\n",
    "title_dict = dict(zip(title, cover_title))\n",
    "train['workclass'] = train['workclass'].map(title_dict)\n",
    "test['workclass'] = test['workclass'].map(title_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "45470ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# United-States가 압도적으로 많기 때문에 따로 나두고, 나머지는 대륙별로 묶기\n",
    "native_country = ['United-States', 'Haiti', 'Mexico', 'Puerto-Rico', 'Philippines',\n",
    "       'Germany', 'Peru', 'Ecuador', 'Iran', 'Thailand',\n",
    "       'Dominican-Republic', 'Poland', 'Scotland', 'Italy', 'Jamaica',\n",
    "       'China', 'Columbia', 'Hungary', 'Portugal', 'Vietnam', 'Taiwan',\n",
    "       'Canada', 'Hong', 'Guatemala', 'El-Salvador', 'England',\n",
    "       'Outlying-US(Guam-USVI-etc)', 'India', 'France', 'Cuba', 'Greece',\n",
    "       'Trinadad&Tobago', 'South', 'Japan', 'Yugoslavia', 'Nicaragua',\n",
    "       'Ireland', 'Cambodia', 'Laos', 'Honduras', 'Holand-Netherlands']\n",
    "conver_native_country = ['United-States', 'North America', 'Asia', 'Europe', 'North America',\n",
    "                         'North America', 'North America', 'North America', 'Asia', 'Europe',\n",
    "                         'North America', 'Asia', 'Asia', 'North America', 'Europe',\n",
    "                         'Asia', 'South America', 'North America', 'Asia', 'Europe',\n",
    "                        'North America', 'Europe', 'Asia', 'Asia', 'North America',\n",
    "                         'South America', 'Europe', 'Europe', 'South America', 'Asia',\n",
    "                         'Europe', 'Asia', 'North America', 'Asia', 'Europe',\n",
    "                         'Asia', 'South America', 'Europe', 'North America', 'Europe', 'Europe']\n",
    "\n",
    "native_country_dict = dict(zip(native_country, conver_native_country))\n",
    "native_country_dict\n",
    "train['native-country']=train['native-country'].map(native_country_dict)\n",
    "test['native-country']=test['native-country'].map(native_country_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "c18e6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fnlwgt는 없는게 더 잘나오길래 지워버림\n",
    "train = train.drop('fnlwgt',axis=1)\n",
    "test= test.drop('fnlwgt',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "85f163ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# 문제/답 분리\\nX_train = train.loc[:,:'native-country']\\ny_train = train['income']\""
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문제/답 분리\n",
    "X_train = train.loc[:,:'native-country']\n",
    "y_train = train['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "6443dbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train = pd.get_dummies(X_train) # 0과 1로만 이루어진 열을 생성\\nX_test = pd.get_dummies(test)'"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.get_dummies(X_train) # 0과 1로만 이루어진 열을 생성\n",
    "X_test = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "de9f2720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d78839",
   "metadata": {},
   "source": [
    "### 모델 학습시키고 결과 제출\n",
    "- knn, decisionTree등은 성능 안 높아지길래 폐기하고\n",
    "- 안배운 모델은 없나? 하고 찾아보던 중 lgbm과 catboost모델 등을 찾아서 사용하기로 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c4824e",
   "metadata": {},
   "source": [
    "https://hyunicecream.tistory.com/5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd924bbd",
   "metadata": {},
   "source": [
    "#### 그리드 서치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9ddf70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ada_model = AdaBoostClassifier()\n",
    "ada_param = {'n_estimators' : [50,150,250],\n",
    "             'learning_rate' : [0.5,1]\n",
    "            }\n",
    "ada_grid = GridSearchCV(ada_model,ada_param,cv = 3)\n",
    "ada_grid.fit(X_train,y_train)\n",
    "print('최고 평균 정확도 수치: {:.4f}'.format(ada_grid.best_score_))\n",
    "print('최적 하이퍼 파라미터: ', ada_grid.best_params_)\n",
    "# 그리드서치 바탕으로 하이퍼파라미터 조정\n",
    "final_ada_model = ada_grid.best_estimator_\"\"\"\n",
    "final_ada_model = AdaBoostClassifier(learning_rate= 1,\n",
    "                                    n_estimators = 250)\n",
    "final_ada_model.fit(X_train,y_train)\n",
    "pre = final_ada_model.predict(X_test)\n",
    "# 정답제출\n",
    "result = pd.read_csv('data/sample_submission.csv')\n",
    "result['income'] = pre\n",
    "result.to_csv('real_real_real_real_real_final_ada_model.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fb1686",
   "metadata": {},
   "source": [
    "- 최고 평균 정확도 수치: 0.8628\n",
    "- 최적 하이퍼 파라미터:  {'learning_rate': 1, 'n_estimators': 250}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cce9f5",
   "metadata": {},
   "source": [
    "- 최고 평균 정확도 수치: 0.8657\n",
    "- 최적 하이퍼 파라미터:  {'learning_rate': 0.01, 'max_depth': 50, 'n_estimators': 800, 'num_leaves': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bd5b5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 7045, number of negative: 22260\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 349\n",
      "[LightGBM] [Info] Number of data points in the train set: 29305, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240403 -> initscore=-1.150473\n",
      "[LightGBM] [Info] Start training from score -1.150473\n"
     ]
    }
   ],
   "source": [
    "\"\"\"lgbm_model = LGBMClassifier()\n",
    "lgbm_param = {\"learning_rate\" : [0.01,0.1,0.2,0.3,0.4,0.5],\n",
    "              \"max_depth\" : [25, 50, 75],\n",
    "              \"num_leaves\" : [100,300,500,900,1200],\n",
    "              \"n_estimators\" : [100, 200, 300,500,800,1000]\n",
    "              }\n",
    "lgbm_grid = GridSearchCV (lgbm_model, lgbm_param, scoring ='accuracy', cv = 3, refit=True, n_jobs=1, verbose=2)\n",
    "lgbm_grid.fit(X_train,y_train)\n",
    "print('최고 평균 정확도 수치: {:.4f}'.format(lgbm_grid.best_score_))\n",
    "print('최적 하이퍼 파라미터: ', lgbm_grid.best_params_)\n",
    "\n",
    "final_lgbm_model = lgbm_grid.best_estimator_\"\"\"\n",
    "final_lgbm_model = LGBMClassifier(learning_rate=0.01,\n",
    "                                 max_depth = 50,\n",
    "                                 n_estimators=800,\n",
    "                                 num_leaves=100)\n",
    "final_lgbm_model.fit(X_train, y_train)\n",
    "pre = final_lgbm_model.predict(X_test)\n",
    "# 정답제출\n",
    "result = pd.read_csv('data/sample_submission.csv')\n",
    "result['income'] = pre\n",
    "result.to_csv('real_real_real_real_real_final_lgbm_model.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36248428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.043583\n",
      "0:\tlearn: 0.6493672\ttotal: 147ms\tremaining: 2m 26s\n",
      "200:\tlearn: 0.2878280\ttotal: 1.67s\tremaining: 6.65s\n",
      "400:\tlearn: 0.2728914\ttotal: 3.2s\tremaining: 4.78s\n",
      "600:\tlearn: 0.2648222\ttotal: 4.64s\tremaining: 3.08s\n",
      "800:\tlearn: 0.2587812\ttotal: 6.21s\tremaining: 1.54s\n",
      "999:\tlearn: 0.2539103\ttotal: 7.76s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "\"\"\"cat_model = CatBoostClassifier()\n",
    "cat_param = {\"depth\" : [4,6,8,10],\n",
    "          \"iterations\" : [250,100,500,1000],\n",
    "          \"learning_rate\" : [0.001,0.01,0.1,0.2,0.3], \n",
    "          \"l2_leaf_reg\" : [2,5,10,20,30],\n",
    "          \"border_count\" : [254]\n",
    "          }\n",
    "cat_grid = GridSearchCV (cat_model, cat_param, scoring ='accuracy', cv = 3, refit=True, n_jobs=1, verbose=2)\n",
    "cat_grid.fit(X_train,y_train)\n",
    "print('최고 평균 정확도 수치: {:.4f}'.format(cat_grid.best_score_))\n",
    "print('최적 하이퍼 파라미터: ', cat_grid.best_params_)\"\"\"\n",
    "\n",
    "final_cat_model = CatBoostClassifier(verbose = 200)\n",
    "final_cat_model.fit(X_train, y_train)\n",
    "pre = final_cat_model.predict(X_test)\n",
    "# 정답제출\n",
    "result = pd.read_csv('data/sample_submission.csv')\n",
    "result['income'] = pre\n",
    "result.to_csv('real_real_real_real_real_final_cat_model.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f9bc85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier()\n",
    "xgb_param = {\"max_depth\": [10,30,50],\n",
    "             \"min_child_weight\" : [1,3,6,10],\n",
    "             \"n_estimators\": [200,300,500,1000]\n",
    "            }\n",
    "xgb_grid = GridSearchCV (xgb_model, xgb_param, scoring ='accuracy', cv = 3, refit=True, n_jobs=1, verbose=2)\n",
    "xgb_grid.fit(X_train,y_train)\n",
    "print('최고 평균 정확도 수치: {:.4f}'.format(xgb_grid.best_score_))\n",
    "print('최적 하이퍼 파라미터: ', xgb_grid.best_params_)\n",
    "\n",
    "final_xgb_model = xgb_grid.best_estimator_\n",
    "final_xgb_model.fit(X_train, y_train)\n",
    "pre = final_xgb_model.predict(X_test)\n",
    "# 정답제출\n",
    "result = pd.read_csv('data/sample_submission.csv')\n",
    "result['income'] = pre\n",
    "result.to_csv('real_real_real_real_real_final_xgb_model.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c224e40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_model = GradientBoostingClassifier()\n",
    "gbm_param = {\"max_depth\" : [4,6,8,10],\n",
    "             \"learning_rate\" : [0.01,0.1,0.3,0.5],\n",
    "             \"n_estimators\" : [100,300,500]\n",
    "            }\n",
    "gbm_grid = GridSearchCV (gbm_model, gbm_param, scoring ='accuracy', cv = 3, refit=True, n_jobs=1, verbose=2)\n",
    "gbm_grid.fit(X_train,y_train)\n",
    "print('최고 평균 정확도 수치: {:.4f}'.format(gbm_grid.best_score_))\n",
    "print('최적 하이퍼 파라미터: ', gbm_grid.best_params_)\n",
    "\n",
    "final_gbm_model = gbm_grid.best_estimator_\n",
    "final_gbm_model.fit(X_train, y_train)\n",
    "pre = final_gbm_model.predict(X_test)\n",
    "# 정답제출\n",
    "result = pd.read_csv('data/sample_submission.csv')\n",
    "result['income'] = pre\n",
    "result.to_csv('real_real_real_real_real_final_gbm_model2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88dfff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg_model = LogisticRegression()\n",
    "lreg_param = {'C' : [1.0, 3, 5, 7, 10],\n",
    "             'max_iter': [50, 100, 300, 500,700, 800]\n",
    "            }\n",
    "lreg_grid = GridSearchCV (lreg_model, lreg_param, scoring ='accuracy', cv = 3, refit=True, n_jobs=1, verbose=2)\n",
    "lreg_grid.fit(X_train,y_train)\n",
    "print('최고 평균 정확도 수치: {:.4f}'.format(lreg_grid.best_score_))\n",
    "print('최적 하이퍼 파라미터: ', lreg_grid.best_params_)\n",
    "final_lreg_model = lreg_grid.best_estimator_\n",
    "final_lreg_model.fit(X_train, y_train)\n",
    "pre = final_lreg_model.predict(X_test)\n",
    "# 정답제출\n",
    "result = pd.read_csv('data/sample_submission.csv')\n",
    "result['income'] = pre\n",
    "result.to_csv('real_real_real_real_real_final_lreg_model.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d758f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_voting_model = VotingClassifier(\n",
    "                        estimators=[\n",
    "                        ('final_ada_mode',final_ada_model),\n",
    "                        ('final_lgbm_model',final_lgbm_model),\n",
    "                        ('final_cat_model',final_cat_model),\n",
    "                        ('final_gbm_model',final_gbm_model),\n",
    "                        ('final_xgb_model',final_xgb_model),\n",
    "                        ('final_lreg_model',final_lreg_model)\n",
    "                        ],\n",
    "                        voting='soft'\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c125496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 7045, number of negative: 22260\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 349\n",
      "[LightGBM] [Info] Number of data points in the train set: 29305, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240403 -> initscore=-1.150473\n",
      "[LightGBM] [Info] Start training from score -1.150473\n",
      "Learning rate set to 0.043583\n",
      "0:\tlearn: 0.6493672\ttotal: 9.76ms\tremaining: 9.75s\n",
      "200:\tlearn: 0.2878280\ttotal: 1.44s\tremaining: 5.74s\n",
      "400:\tlearn: 0.2728914\ttotal: 2.88s\tremaining: 4.29s\n",
      "600:\tlearn: 0.2648222\ttotal: 4.36s\tremaining: 2.89s\n",
      "800:\tlearn: 0.2587812\ttotal: 5.83s\tremaining: 1.45s\n",
      "999:\tlearn: 0.2539103\ttotal: 7.46s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;final_ada_mode&#x27;,\n",
       "                              AdaBoostClassifier(learning_rate=1,\n",
       "                                                 n_estimators=250)),\n",
       "                             (&#x27;final_lgbm_model&#x27;,\n",
       "                              LGBMClassifier(learning_rate=0.01, max_depth=50,\n",
       "                                             n_estimators=800,\n",
       "                                             num_leaves=100)),\n",
       "                             (&#x27;final_cat_model&#x27;,\n",
       "                              &lt;catboost.core.CatBoostClassifier object at 0x0000016567607B50&gt;),\n",
       "                             (&#x27;final_gbm_model&#x27;,\n",
       "                              GradientBoostingClassifier(max_depth=6)),\n",
       "                             (&#x27;final...\n",
       "                                            learning_rate=None, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=30,\n",
       "                                            max_leaves=None, min_child_weight=6,\n",
       "                                            missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=200, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=None, ...)),\n",
       "                             (&#x27;final_lreg_model&#x27;,\n",
       "                              LogisticRegression(C=10, max_iter=500))],\n",
       "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;final_ada_mode&#x27;,\n",
       "                              AdaBoostClassifier(learning_rate=1,\n",
       "                                                 n_estimators=250)),\n",
       "                             (&#x27;final_lgbm_model&#x27;,\n",
       "                              LGBMClassifier(learning_rate=0.01, max_depth=50,\n",
       "                                             n_estimators=800,\n",
       "                                             num_leaves=100)),\n",
       "                             (&#x27;final_cat_model&#x27;,\n",
       "                              &lt;catboost.core.CatBoostClassifier object at 0x0000016567607B50&gt;),\n",
       "                             (&#x27;final_gbm_model&#x27;,\n",
       "                              GradientBoostingClassifier(max_depth=6)),\n",
       "                             (&#x27;final...\n",
       "                                            learning_rate=None, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=30,\n",
       "                                            max_leaves=None, min_child_weight=6,\n",
       "                                            missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=200, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=None, ...)),\n",
       "                             (&#x27;final_lreg_model&#x27;,\n",
       "                              LogisticRegression(C=10, max_iter=500))],\n",
       "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_ada_mode</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(learning_rate=1, n_estimators=250)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_lgbm_model</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.01, max_depth=50, n_estimators=800,\n",
       "               num_leaves=100)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_cat_model</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x0000016567607B50&gt;</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_gbm_model</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_depth=6)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_xgb_model</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=30, max_leaves=None,\n",
       "              min_child_weight=6, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_lreg_model</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, max_iter=500)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('final_ada_mode',\n",
       "                              AdaBoostClassifier(learning_rate=1,\n",
       "                                                 n_estimators=250)),\n",
       "                             ('final_lgbm_model',\n",
       "                              LGBMClassifier(learning_rate=0.01, max_depth=50,\n",
       "                                             n_estimators=800,\n",
       "                                             num_leaves=100)),\n",
       "                             ('final_cat_model',\n",
       "                              <catboost.core.CatBoostClassifier object at 0x0000016567607B50>),\n",
       "                             ('final_gbm_model',\n",
       "                              GradientBoostingClassifier(max_depth=6)),\n",
       "                             ('final...\n",
       "                                            learning_rate=None, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=30,\n",
       "                                            max_leaves=None, min_child_weight=6,\n",
       "                                            missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            multi_strategy=None,\n",
       "                                            n_estimators=200, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=None, ...)),\n",
       "                             ('final_lreg_model',\n",
       "                              LogisticRegression(C=10, max_iter=500))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습\n",
    "final_voting_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98ae98d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "pre = final_voting_model.predict(X_test)\n",
    "# 정답제출\n",
    "result = pd.read_csv('data/sample_submission.csv')\n",
    "result['income'] = pre\n",
    "result.to_csv('real_real_real_real_final_voting_model.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0826fd",
   "metadata": {},
   "source": [
    "voting 모델끼리 voting 시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "330b2563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 7045, number of negative: 22260\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 349\n",
      "[LightGBM] [Info] Number of data points in the train set: 29305, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240403 -> initscore=-1.150473\n",
      "[LightGBM] [Info] Start training from score -1.150473\n",
      "Learning rate set to 0.043583\n",
      "0:\tlearn: 0.6493672\ttotal: 7.31ms\tremaining: 7.3s\n",
      "200:\tlearn: 0.2878280\ttotal: 1.71s\tremaining: 6.79s\n",
      "400:\tlearn: 0.2728914\ttotal: 3.32s\tremaining: 4.96s\n",
      "600:\tlearn: 0.2648222\ttotal: 4.84s\tremaining: 3.21s\n",
      "800:\tlearn: 0.2587812\ttotal: 6.42s\tremaining: 1.59s\n",
      "999:\tlearn: 0.2539103\ttotal: 8.05s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "final_voting_model1 = VotingClassifier(\n",
    "                        estimators=[\n",
    "                        ('final_ada_mode',final_ada_model),\n",
    "                        ('final_lgbm_model',final_lgbm_model),\n",
    "                        ('final_cat_model',final_cat_model)\n",
    "                        ],\n",
    "                        voting='soft'\n",
    "                        )\n",
    "# 학습\n",
    "final_voting_model1.fit(X_train,y_train)\n",
    "# 예측\n",
    "pre = final_voting_model1.predict(X_test)\n",
    "# 정답제출\n",
    "result = pd.read_csv('data/sample_submission.csv')\n",
    "result['income'] = pre\n",
    "result.to_csv('real_real_real_real_real_real_final_voting_model1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e736e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_voting_model3 = VotingClassifier(\n",
    "                        estimators=[\n",
    "                        ('final_gbm_model',final_gbm_model),\n",
    "                        ('final_xgb_model',final_xgb_model),\n",
    "                        ('final_lreg_model',final_lreg_model)\n",
    "                        ],\n",
    "                        voting='soft'\n",
    "                        )\n",
    "# 학습\n",
    "final_voting_model3.fit(X_train,y_train)\n",
    "pre = final_voting_model3.predict(X_test)\n",
    "# 정답제출\n",
    "result = pd.read_csv('data/sample_submission.csv')\n",
    "result['income'] = pre\n",
    "result.to_csv('real_real_real_real_real_real_final_voting_model3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21a83c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 7045, number of negative: 22260\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 349\n",
      "[LightGBM] [Info] Number of data points in the train set: 29305, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240403 -> initscore=-1.150473\n",
      "[LightGBM] [Info] Start training from score -1.150473\n",
      "Learning rate set to 0.043583\n",
      "0:\tlearn: 0.6493672\ttotal: 7.76ms\tremaining: 7.76s\n",
      "200:\tlearn: 0.2878280\ttotal: 1.33s\tremaining: 5.29s\n",
      "400:\tlearn: 0.2728914\ttotal: 2.65s\tremaining: 3.96s\n",
      "600:\tlearn: 0.2648222\ttotal: 3.96s\tremaining: 2.63s\n",
      "800:\tlearn: 0.2587812\ttotal: 5.28s\tremaining: 1.31s\n",
      "999:\tlearn: 0.2539103\ttotal: 6.68s\tremaining: 0us\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 7045, number of negative: 22260\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 349\n",
      "[LightGBM] [Info] Number of data points in the train set: 29305, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240403 -> initscore=-1.150473\n",
      "[LightGBM] [Info] Start training from score -1.150473\n",
      "Learning rate set to 0.043583\n",
      "0:\tlearn: 0.6493672\ttotal: 7.13ms\tremaining: 7.13s\n",
      "200:\tlearn: 0.2878280\ttotal: 1.35s\tremaining: 5.39s\n",
      "400:\tlearn: 0.2728914\ttotal: 2.82s\tremaining: 4.21s\n",
      "600:\tlearn: 0.2648222\ttotal: 4.24s\tremaining: 2.81s\n",
      "800:\tlearn: 0.2587812\ttotal: 5.57s\tremaining: 1.38s\n",
      "999:\tlearn: 0.2539103\ttotal: 6.95s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "real_final_voting_model = VotingClassifier(\n",
    "                                            estimators=[\n",
    "                                            ('final_voting_model1',final_voting_model1),                                            \n",
    "                                            ('final_voting_model3',final_voting_model3)\n",
    "                                            ],\n",
    "                                            voting='soft'\n",
    "                                            )\n",
    "# 학습\n",
    "real_final_voting_model.fit(X_train,y_train)\n",
    "pre = real_final_voting_model.predict(X_test)\n",
    "# 정답제출\n",
    "result = pd.read_csv('data/sample_submission.csv')\n",
    "result['income'] = pre\n",
    "result.to_csv('real_real_real_real_real_real_real_real_final_voting_model.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f1decd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32df78e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
